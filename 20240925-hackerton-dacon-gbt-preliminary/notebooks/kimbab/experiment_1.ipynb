{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e227fc5-f068-4883-8b75-2c968440351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, AutoModel, AutoTokenizer, BigBirdForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df4bcf3-d3d5-4673-a701-680f5c4165b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c3c5c4-0528-4a22-a6c0-6baee5048949",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 1e-4, # changed 3e-5 to 3e-4 to 1e-4\n",
    "    \"epoch\": 30,\n",
    "    \"batch_size\": 64,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"tokenizer_max_len\": 256,\n",
    "    # https://huggingface.co/docs/transformers/v4.20.1/en/model_doc/big_bird\n",
    "    # https://huggingface.co/blog/big-bird\n",
    "    \"attention_type\": \"original_full\", # original_full, block_sparse\n",
    "}\n",
    "\n",
    "CFG = SimpleNamespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7decf8e-3979-427a-b418-163594f088ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_path = \"/root/dacon-2024-gbt-hackerton\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f98caa5-092d-4c83-8adb-95e2ab1add74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(root_path, \"./train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(root_path, \"./test.csv\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59f2beed-5c3c-492a-b2e4-0a49872e99ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at monologg/kobigbird-bert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobigbird-bert-base\")  # BertTokenizer\n",
    "model = BigBirdForSequenceClassification.from_pretrained(\n",
    "    'monologg/kobigbird-bert-base', \n",
    "    num_labels=len(train_df['분류'].unique()), \n",
    "    attention_type=CFG.attention_type\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb58d8c6-9e19-4d15-9e0a-8a541f3c4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128, preprocess_datarows=False):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.encodings = []\n",
    "        self._preprocess_datarows = preprocess_datarows\n",
    "        if preprocess_datarows:\n",
    "            print(f\"Using {preprocess_datarows=}\")\n",
    "            self.encodings = self.tokenizer(\n",
    "                self.texts,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if self._preprocess_datarows:\n",
    "            return {\n",
    "                'input_ids': self.encodings['input_ids'][item],\n",
    "                'attention_mask': self.encodings['attention_mask'][item],\n",
    "                'labels': torch.tensor(self.labels[item], dtype=torch.long) if self.labels is not None else -1\n",
    "            }\n",
    "        \n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item] if self.labels is not None else -1\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529aee13-6ebd-47a0-87af-9e3d3c561dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocess_datarows=True\n",
      "Using preprocess_datarows=True\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "# train_df['제목_키워드'] = train_df['제목'] + ' ' + train_df['키워드']\n",
    "# test_df['제목_키워드'] = test_df['제목'] + ' ' + test_df['키워드']\n",
    "def remove_duplicates(text):\n",
    "    return ' '.join(list(dict.fromkeys(text.split(\",\"))))\n",
    "\n",
    "train_df['제목_키워드'] = train_df['키워드'].apply(remove_duplicates)\n",
    "test_df['제목_키워드'] = test_df['키워드'].apply(remove_duplicates)\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = {label: i for i, label in enumerate(train_df['분류'].unique())}\n",
    "train_df['label'] = train_df['분류'].map(label_encoder)\n",
    "\n",
    "# 데이터 분할 (train -> train + validation)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['분류'], random_state=42)\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = TextDataset(train_df.제목_키워드.tolist(), train_df.label.tolist(), tokenizer, max_len=CFG.tokenizer_max_len, preprocess_datarows=True)\n",
    "val_dataset = TextDataset(val_df.제목_키워드.tolist(), val_df.label.tolist(), tokenizer,  max_len=CFG.tokenizer_max_len, preprocess_datarows=True)\n",
    "test_dataset = TextDataset(test_df.제목_키워드.tolist(), None, tokenizer)  # 라벨 없음\n",
    "\n",
    "# 데이터 로더 생성\n",
    "num_workers = 0  # 적절한 값으로 조정하세요\n",
    "pin_memory = True\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf3e5d-cd28-4269-b39e-f0e4bfda8db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70e5e904-0b32-42f3-98c4-365ed0567846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>분류</th>\n",
       "      <th>제목</th>\n",
       "      <th>키워드</th>\n",
       "      <th>제목_키워드</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35146</th>\n",
       "      <td>TRAIN_35146</td>\n",
       "      <td>경제:부동산</td>\n",
       "      <td>매물 쌓이고 거래량도 '뚝' 집값 안정화 '조짐'</td>\n",
       "      <td>매물,거래량,조짐,집값,안정,아시아투데이,박지숙,서울,포함,매물,수도,아파트,거래량...</td>\n",
       "      <td>매물 거래량 조짐 집값 안정 아시아투데이 박지숙 서울 포함 수도 아파트 매수세 추세...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7317</th>\n",
       "      <td>TRAIN_07317</td>\n",
       "      <td>스포츠:야구</td>\n",
       "      <td>CJ슈퍼레이스 GT1 2위 개그맨 한민관, 10년차 레이서의 관록 보여줘</td>\n",
       "      <td>한민관,CJ,슈퍼,레이스,GT1,개그맨,10년,레이서,관록,개그맨,한민관,레이서,입...</td>\n",
       "      <td>한민관 CJ 슈퍼 레이스 GT1 개그맨 10년 레이서 관록 입지 소속 레이싱 비트알...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51465</th>\n",
       "      <td>TRAIN_51465</td>\n",
       "      <td>정치:청와대</td>\n",
       "      <td>용인에서 2번 민생토론회 연 尹 \"특례시 지원 특별법 제정, 반도체 고속도로 신속 추진\"</td>\n",
       "      <td>용인,민생,토론회,특례시,제정,지원,특별법,반도체,고속도,신속,추진,윤석열,대통령,...</td>\n",
       "      <td>용인 민생 토론회 특례시 제정 지원 특별법 반도체 고속도 신속 추진 윤석열 대통령 ...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44057</th>\n",
       "      <td>TRAIN_44057</td>\n",
       "      <td>경제:산업_기업</td>\n",
       "      <td>故 조양호 회장 2주기 한진그룹, 난기류 뚫고 '비상'</td>\n",
       "      <td>조양호,회장,한진그룹,난기류,비상,아시아투데이,정석만,회장,조양호,한진그룹,세상,2...</td>\n",
       "      <td>조양호 회장 한진그룹 난기류 비상 아시아투데이 정석만 세상 2년 별세 경영 분쟁 감...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20498</th>\n",
       "      <td>TRAIN_20498</td>\n",
       "      <td>스포츠:골프</td>\n",
       "      <td>4승 고지 누가 먼저 오르나 ‘트로이카’ 박현경 박지영 이예원 격돌</td>\n",
       "      <td>고지,트로이카,박현경,박지영,이예원,격돌,출격,개막,KG,레이디스,오픈,동반,대회,...</td>\n",
       "      <td>고지 트로이카 박현경 박지영 이예원 격돌 출격 개막 KG 레이디스 오픈 동반 대회 ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47885</th>\n",
       "      <td>TRAIN_47885</td>\n",
       "      <td>경제:경제일반</td>\n",
       "      <td>강서구 보험회사 5명 등 서울 어제 37명 확진</td>\n",
       "      <td>5명,강서구,보험,회사,서울,확진,서울,신종,코로나바이러스,감염증,코로나19,확진자...</td>\n",
       "      <td>5명 강서구 보험 회사 서울 확진 신종 코로나바이러스 감염증 코로나19 확진자 발생...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14003</th>\n",
       "      <td>TRAIN_14003</td>\n",
       "      <td>경제:반도체</td>\n",
       "      <td>이상일 용인시장, 반도체 국가산단 적극협조...부지 내 이주대책 등 협조 필요</td>\n",
       "      <td>이상일,용인,시장,적극협조,반도체,국가산단,적극,협조,부지,이주대책,협조,회의서,산...</td>\n",
       "      <td>이상일 용인 시장 적극협조 반도체 국가산단 적극 협조 부지 이주대책 회의서 산업 주...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20857</th>\n",
       "      <td>TRAIN_20857</td>\n",
       "      <td>경제:부동산</td>\n",
       "      <td>더퍼스트한양, '더챔버 라티파니' 내달 공급</td>\n",
       "      <td>더퍼스트한양,라티파니,내달,공급,아시아투데이,이민영,더퍼스트한양,동탄2,경기도,화성...</td>\n",
       "      <td>더퍼스트한양 라티파니 내달 공급 아시아투데이 이민영 동탄2 경기도 화성시 동탄 신도...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48642</th>\n",
       "      <td>TRAIN_48642</td>\n",
       "      <td>사회:사건_사고</td>\n",
       "      <td>남경필 전 지사 장남 또 필로폰 투약 구속영장 기각 닷새만</td>\n",
       "      <td>남경필,지사,장남,필로폰,투약,구속영장,기각,닷새,필로폰,투약,혐의,체포,법원,구속...</td>\n",
       "      <td>남경필 지사 장남 필로폰 투약 구속영장 기각 닷새 혐의 체포 법원 구속 영장 경기도...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49684</th>\n",
       "      <td>TRAIN_49684</td>\n",
       "      <td>경제:유통</td>\n",
       "      <td>다 짓고도 못 판 집 늘었다 도내 미분양 총 7천226가구</td>\n",
       "      <td>도내,7천,가구,경기지역,준공,미분양,지속적,증가,주택,경기,회복세,주장,민간,경기...</td>\n",
       "      <td>도내 7천 가구 경기지역 준공 미분양 지속적 증가 주택 경기 회복세 주장 민간 경기...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22127 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID        분류  \\\n",
       "35146  TRAIN_35146    경제:부동산   \n",
       "7317   TRAIN_07317    스포츠:야구   \n",
       "51465  TRAIN_51465    정치:청와대   \n",
       "44057  TRAIN_44057  경제:산업_기업   \n",
       "20498  TRAIN_20498    스포츠:골프   \n",
       "...            ...       ...   \n",
       "47885  TRAIN_47885   경제:경제일반   \n",
       "14003  TRAIN_14003    경제:반도체   \n",
       "20857  TRAIN_20857    경제:부동산   \n",
       "48642  TRAIN_48642  사회:사건_사고   \n",
       "49684  TRAIN_49684     경제:유통   \n",
       "\n",
       "                                                      제목  \\\n",
       "35146                        매물 쌓이고 거래량도 '뚝' 집값 안정화 '조짐'   \n",
       "7317            CJ슈퍼레이스 GT1 2위 개그맨 한민관, 10년차 레이서의 관록 보여줘   \n",
       "51465  용인에서 2번 민생토론회 연 尹 \"특례시 지원 특별법 제정, 반도체 고속도로 신속 추진\"   \n",
       "44057                     故 조양호 회장 2주기 한진그룹, 난기류 뚫고 '비상'   \n",
       "20498              4승 고지 누가 먼저 오르나 ‘트로이카’ 박현경 박지영 이예원 격돌   \n",
       "...                                                  ...   \n",
       "47885                         강서구 보험회사 5명 등 서울 어제 37명 확진   \n",
       "14003        이상일 용인시장, 반도체 국가산단 적극협조...부지 내 이주대책 등 협조 필요   \n",
       "20857                           더퍼스트한양, '더챔버 라티파니' 내달 공급   \n",
       "48642                   남경필 전 지사 장남 또 필로폰 투약 구속영장 기각 닷새만   \n",
       "49684                   다 짓고도 못 판 집 늘었다 도내 미분양 총 7천226가구   \n",
       "\n",
       "                                                     키워드  \\\n",
       "35146  매물,거래량,조짐,집값,안정,아시아투데이,박지숙,서울,포함,매물,수도,아파트,거래량...   \n",
       "7317   한민관,CJ,슈퍼,레이스,GT1,개그맨,10년,레이서,관록,개그맨,한민관,레이서,입...   \n",
       "51465  용인,민생,토론회,특례시,제정,지원,특별법,반도체,고속도,신속,추진,윤석열,대통령,...   \n",
       "44057  조양호,회장,한진그룹,난기류,비상,아시아투데이,정석만,회장,조양호,한진그룹,세상,2...   \n",
       "20498  고지,트로이카,박현경,박지영,이예원,격돌,출격,개막,KG,레이디스,오픈,동반,대회,...   \n",
       "...                                                  ...   \n",
       "47885  5명,강서구,보험,회사,서울,확진,서울,신종,코로나바이러스,감염증,코로나19,확진자...   \n",
       "14003  이상일,용인,시장,적극협조,반도체,국가산단,적극,협조,부지,이주대책,협조,회의서,산...   \n",
       "20857  더퍼스트한양,라티파니,내달,공급,아시아투데이,이민영,더퍼스트한양,동탄2,경기도,화성...   \n",
       "48642  남경필,지사,장남,필로폰,투약,구속영장,기각,닷새,필로폰,투약,혐의,체포,법원,구속...   \n",
       "49684  도내,7천,가구,경기지역,준공,미분양,지속적,증가,주택,경기,회복세,주장,민간,경기...   \n",
       "\n",
       "                                                  제목_키워드  label  \n",
       "35146  매물 거래량 조짐 집값 안정 아시아투데이 박지숙 서울 포함 수도 아파트 매수세 추세...     10  \n",
       "7317   한민관 CJ 슈퍼 레이스 GT1 개그맨 10년 레이서 관록 입지 소속 레이싱 비트알...     50  \n",
       "51465  용인 민생 토론회 특례시 제정 지원 특별법 반도체 고속도 신속 추진 윤석열 대통령 ...     43  \n",
       "44057  조양호 회장 한진그룹 난기류 비상 아시아투데이 정석만 세상 2년 별세 경영 분쟁 감...     25  \n",
       "20498  고지 트로이카 박현경 박지영 이예원 격돌 출격 개막 KG 레이디스 오픈 동반 대회 ...     26  \n",
       "...                                                  ...    ...  \n",
       "47885  5명 강서구 보험 회사 서울 확진 신종 코로나바이러스 감염증 코로나19 확진자 발생...     16  \n",
       "14003  이상일 용인 시장 적극협조 반도체 국가산단 적극 협조 부지 이주대책 회의서 산업 주...     33  \n",
       "20857  더퍼스트한양 라티파니 내달 공급 아시아투데이 이민영 동탄2 경기도 화성시 동탄 신도...     10  \n",
       "48642  남경필 지사 장남 필로폰 투약 구속영장 기각 닷새 혐의 체포 법원 구속 영장 경기도...     21  \n",
       "49684  도내 7천 가구 경기지역 준공 미분양 지속적 증가 주택 경기 회복세 주장 민간 경기...     27  \n",
       "\n",
       "[22127 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['분류'] != '지역']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b79a76f-98de-4c4a-a167-83069321faaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a6c1c1f9cc491bbaa7fbd4cc6a99b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(HTML(value='\\n<div id=\"ifr-pyg-00062303e9dc7117Smzp4KeUa50RDP1b\" style=\"height: auto\">\\n    <hea…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    window.addEventListener(\"message\", function(event) {\n",
       "        const backgroundMap = {\n",
       "            \"dark\": \"hsl(240 10% 3.9%)\",\n",
       "            \"light\": \"hsl(0 0 100%)\",\n",
       "        };\n",
       "        const colorMap = {\n",
       "            \"dark\": \"hsl(0 0% 98%)\",\n",
       "            \"light\": \"hsl(240 10% 3.9%)\",\n",
       "        };\n",
       "        if (event.data.action === \"changeAppearance\" && event.data.gid === \"00062303e9dc7117Smzp4KeUa50RDP1b\") {\n",
       "            var iframe = document.getElementById(\"gwalker-00062303e9dc7117Smzp4KeUa50RDP1b\");\n",
       "            iframe.style.background  = backgroundMap[event.data.appearance];\n",
       "            iframe.style.color = colorMap[event.data.appearance];\n",
       "        }\n",
       "    });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "walker = pyg.walk(train_df[train_df['분류'] != '지역'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da3fc6a5-5d44-4dec-b19f-700bd0431f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "\n",
    "# 옵티마이저 및 학습 파라미터 설정\n",
    "optimizer = AdamW(model.parameters(), lr=CFG.learning_rate, weight_decay=CFG.weight_decay)\n",
    "\n",
    "# Calculate total number of training steps\n",
    "total_steps = len(train_loader) * CFG.epoch\n",
    "\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * total_steps),  # 10% of total steps for warmup\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc1f74-2b1f-484b-bed3-01ccfe95b955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mryanbae\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20240926_071637-li1yutsd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ryanbae/dacon-gbt-2024-hackerton/runs/li1yutsd' target=\"_blank\">graceful-tree-15</a></strong> to <a href='https://wandb.ai/ryanbae/dacon-gbt-2024-hackerton' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ryanbae/dacon-gbt-2024-hackerton' target=\"_blank\">https://wandb.ai/ryanbae/dacon-gbt-2024-hackerton</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ryanbae/dacon-gbt-2024-hackerton/runs/li1yutsd' target=\"_blank\">https://wandb.ai/ryanbae/dacon-gbt-2024-hackerton/runs/li1yutsd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:   0%|          | 0/683 [00:00<?, ?it/s]Attention type 'block_sparse' is not possible if sequence_length: 256 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
      "Epoch 1/30: 100%|██████████| 683/683 [04:51<00:00,  2.34it/s]\n",
      "Validating: 100%|██████████| 171/171 [00:24<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Average Training Loss: 2.2011\n",
      "Validation F1 Score: 0.2198\n",
      "Best Validation F1 Score: 0.0000\n",
      "Current learning rate: 3.3333333333333335e-05\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 683/683 [04:35<00:00,  2.47it/s]\n",
      "Validating: 100%|██████████| 171/171 [00:24<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "Average Training Loss: 0.9357\n",
      "Validation F1 Score: 0.4505\n",
      "Best Validation F1 Score: 0.2198\n",
      "Current learning rate: 6.666666666666667e-05\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30:  76%|███████▋  | 522/683 [03:30<01:05,  2.48it/s]"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "w_run = wandb.init(\n",
    "    project=\"dacon-gbt-2024-hackerton\",\n",
    "    config=CFG\n",
    ")\n",
    "\n",
    "# 학습\n",
    "model.train()\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 3\n",
    "best_val_f1 = 0\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(CFG.epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{CFG.epoch}'):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc='Validating'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(preds.cpu().tolist())\n",
    "            val_true_labels.extend(labels.cpu().tolist())\n",
    "    \n",
    "    # 검증 결과 출력\n",
    "    val_f1 = f1_score(val_true_labels, val_predictions, average='macro')\n",
    "\n",
    "    # Log metrics to wandb\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": avg_train_loss,\n",
    "        \"val_f1_score\": val_f1,\n",
    "        \"learning_rate\": scheduler.get_last_lr()[0],  # Log the current learning rate\n",
    "        \"best_val_f1\": best_val_f1\n",
    "    })\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{CFG.epoch}\")\n",
    "    print(f\"Average Training Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "    print(f\"Best Validation F1 Score: {best_val_f1:.4f}\")\n",
    "    print(f\"Current learning rate: {scheduler.get_last_lr()[0]}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "     # Early stopping check\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        counter = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        counter += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if counter >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f94d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec8cfe9a-9955-44d5-a9b5-72520c0c2b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 366/366 [00:36<00:00,  9.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 세트 추론\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs.logits, dim=1)\n",
    "        test_predictions.extend(preds.cpu().tolist())\n",
    "\n",
    "# 라벨 디코딩\n",
    "label_decoder = {i: label for label, i in label_encoder.items()}\n",
    "decoded_predictions = [label_decoder[pred] for pred in test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "430f427a-9d1e-4f4f-94b1-7daddf52e0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graceful-tree-15'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_run.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85c00041-f875-483c-b1f9-79846fbf124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(os.path.join(root_path, \"./sample_submission.csv\"))\n",
    "sample_submission[\"분류\"] = decoded_predictions\n",
    "submission_filepath = f\"./{w_run.name}.csv\"\n",
    "sample_submission.to_csv(submission_filepath, encoding='UTF-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "476be297-24ec-4bc2-b6c2-60dbb355e266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isSubmitted': True, 'detail': 'Success'}\n"
     ]
    }
   ],
   "source": [
    "from dacon_submit_api import dacon_submit_api \n",
    "\n",
    "dacon_token = 'd5ea5ec7e519de6412291ab093463dc54315baa080104aeee57ae0ab51543149'\n",
    "result = dacon_submit_api.post_submission_file(\n",
    "submission_filepath, \n",
    "dacon_token, \n",
    "'236372', \n",
    "'김밥조아', \n",
    "'submission 메모 내용' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c9dab-04c9-41a2-8058-802b3804617d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
